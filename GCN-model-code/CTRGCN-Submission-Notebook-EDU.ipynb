{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90da039c",
   "metadata": {},
   "source": [
    "\n",
    "# MABe CTR-GCN Submission (Educational Scaffold)\n",
    "\n",
    "This notebook is an **educational, fully annotated scaffold** for building a CTR-GCN-based solution for the\n",
    "[MABe Mouse Behavior Detection](https://www.kaggle.com/competitions/MABe-mouse-behavior-detection) challenge.\n",
    "\n",
    "It mirrors the structure of your `CTRGCN-model-baseline.py` file, but focuses on **clarity and learning**:\n",
    "- Configuration and modes\n",
    "- Data loading and batching\n",
    "- Skeleton definition and adjacency\n",
    "- CTR-GCN model classes (1/2/4 stream variants)\n",
    "- Input preparation (coords, deltas, bones)\n",
    "- Training, tuning, and submission hooks\n",
    "\n",
    "Most heavy logic is left as **TODO blocks** so you can paste in or adapt your full implementations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e212450",
   "metadata": {},
   "source": [
    "\n",
    "## 1. High-Level Pipeline\n",
    "\n",
    "Three major phases in the CTR-GCN workflow:\n",
    "\n",
    "1. **Offline Training / Validation** (local machine or cluster)\n",
    "2. **Offline Hyperparameter Tuning** (optional, per-stream)\n",
    "3. **Online Submission** (Kaggle: inference-only, using pre-trained models)\n",
    "\n",
    "This notebook is primarily designed for **inference and education**, assuming heavy training\n",
    "is done offline using your Python script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a9431",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Configuration Panel\n",
    "\n",
    "Edit this cell to control run mode, stream mode, and root paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== RUN / STREAM MODES =====================================================\n",
    "\n",
    "# What should this notebook do?\n",
    "# - \"dev\"    : tiny sanity-check on a small subset (once TODO blocks are filled)\n",
    "# - \"submit\" : load pre-trained models and generate submission.csv on Kaggle\n",
    "RUN_MODE = \"dev\"   # change to \"submit\" for actual Kaggle submission\n",
    "\n",
    "# CTR-GCN stream mode:\n",
    "# - \"one\"  : single stream with merged coords/delta/bone/bone_delta\n",
    "# - \"two\"  : two streams (coords+bone, delta+bone_delta)\n",
    "# - \"four\" : four independent streams\n",
    "STREAM_MODE = \"one\"\n",
    "\n",
    "# Paths (adjust for local vs Kaggle)\n",
    "DATA_ROOT = \"../input/MABe-mouse-behavior-detection\"\n",
    "MODEL_ROOT = \"CTR-GCN-Models\"\n",
    "TUNING_ROOT = \"tuning_results\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84aab9",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57afa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec00e59",
   "metadata": {},
   "source": [
    "\n",
    "## 4. CTR-GCN Configuration & Helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3447598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class CTRGCNConfig:\n",
    "    \"\"\"Configuration object for the CTR-GCN pipeline (simplified educational version).\"\"\"\n",
    "\n",
    "    mode: str = \"dev\"\n",
    "    stream_mode: str = \"one\"\n",
    "\n",
    "    max_videos: int | None = 2\n",
    "    max_batches: int | None = 5\n",
    "    max_windows: int | None = 50\n",
    "\n",
    "    use_delta: bool = True\n",
    "    use_bone: bool = True\n",
    "    use_bone_delta: bool = True\n",
    "\n",
    "    in_channels_single_stream: int = 8\n",
    "    in_channels_streamA: int = 4\n",
    "    in_channels_streamB: int = 4\n",
    "    in_channels_coords_only: int = 2\n",
    "    in_channels_delta_only: int = 2\n",
    "    in_channels_bone_only: int = 2\n",
    "    in_channels_bone_delta_only: int = 2\n",
    "\n",
    "\n",
    "def get_stream_mode_tag(cfg: CTRGCNConfig) -> str:\n",
    "    mode = getattr(cfg, \"stream_mode\", \"one\")\n",
    "    assert mode in {\"one\", \"two\", \"four\"}\n",
    "    return mode\n",
    "\n",
    "\n",
    "def get_stream_model_dir(cfg: CTRGCNConfig) -> str:\n",
    "    root = MODEL_ROOT\n",
    "    tag = get_stream_mode_tag(cfg)\n",
    "    sub = {\n",
    "        \"one\": \"one_stream\",\n",
    "        \"two\": \"two_stream\",\n",
    "        \"four\": \"four_stream\",\n",
    "    }[tag]\n",
    "    path = os.path.join(root, sub)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac044ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_best_params_path_for_stream(cfg: CTRGCNConfig) -> str:\n",
    "    os.makedirs(TUNING_ROOT, exist_ok=True)\n",
    "    mode = getattr(cfg, \"stream_mode\", \"one\")\n",
    "    assert mode in {\"one\", \"two\", \"four\"}\n",
    "    return os.path.join(TUNING_ROOT, f\"best_params_{mode}.csv\")\n",
    "\n",
    "\n",
    "def load_best_params_csv_for_config(config: CTRGCNConfig) -> dict | None:\n",
    "    path = get_best_params_path_for_stream(config)\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45771e1",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Mouse Skeleton: Joints & Adjacency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MASTER_MOUSE_JOINT_ORDER = [\n",
    "    \"nose\",\n",
    "    \"head\",\n",
    "    \"headpiece_topfrontleft\",\n",
    "    \"headpiece_topfrontright\",\n",
    "    \"headpiece_topbackleft\",\n",
    "    \"headpiece_topbackright\",\n",
    "    \"headpiece_bottomfrontleft\",\n",
    "    \"headpiece_bottomfrontright\",\n",
    "    \"headpiece_bottombackleft\",\n",
    "    \"headpiece_bottombackright\",\n",
    "    \"ear_left\",\n",
    "    \"ear_right\",\n",
    "    \"neck\",\n",
    "    \"forepaw_left\",\n",
    "    \"forepaw_right\",\n",
    "    \"body_center\",\n",
    "    \"lateral_left\",\n",
    "    \"lateral_right\",\n",
    "    \"spine_1\",\n",
    "    \"spine_2\",\n",
    "    \"hip_left\",\n",
    "    \"hip_right\",\n",
    "    \"hindpaw_left\",\n",
    "    \"hindpaw_right\",\n",
    "    \"tail_base\",\n",
    "    \"tail_middle_1\",\n",
    "    \"tail_middle_2\",\n",
    "    \"tail_midpoint\",\n",
    "    \"tail_tip\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_ordered_joints_and_adjacency(body_parts_tracked: list[str]) -> tuple[list[str], np.ndarray]:\n",
    "    ordered_joints = [bp for bp in MASTER_MOUSE_JOINT_ORDER if bp in body_parts_tracked]\n",
    "    V = len(ordered_joints)\n",
    "    adjacency = np.zeros((V, V), dtype=np.float32)\n",
    "    for i in range(V - 1):\n",
    "        adjacency[i, i + 1] = 1.0\n",
    "        adjacency[i + 1, i] = 1.0\n",
    "    return ordered_joints, adjacency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b74840",
   "metadata": {},
   "source": [
    "\n",
    "## 6. CTR-GCN Model Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d926be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _normalize_adjacency_chain(adjacency: np.ndarray) -> np.ndarray:\n",
    "    V = adjacency.shape[0]\n",
    "    A = adjacency.astype(np.float32).copy()\n",
    "    A += np.eye(V, dtype=np.float32)\n",
    "    row_sum = A.sum(axis=1, keepdims=True)\n",
    "    row_sum[row_sum == 0.0] = 1.0\n",
    "    return A / row_sum\n",
    "\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, adjacency: np.ndarray):\n",
    "        super().__init__()\n",
    "        A_norm = _normalize_adjacency_chain(adjacency)\n",
    "        self.register_buffer(\"A\", torch.from_numpy(A_norm))\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.einsum(\"ncvT,vw->ncwT\", x, self.A)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, adjacency: np.ndarray,\n",
    "                 stride: int = 1, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.gcn = GraphConv(in_channels, out_channels, adjacency)\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(1, 3),\n",
    "                padding=(0, 1),\n",
    "                stride=(1, stride),\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        if (in_channels != out_channels) or (stride != 1):\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(1, stride), bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        res = self.residual(x)\n",
    "        x = self.gcn(x)\n",
    "        x = self.tcn(x)\n",
    "        x = x + res\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e262479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CTRGCNMinimal(nn.Module):\n",
    "    def __init__(self, in_channels: int, num_classes: int,\n",
    "                 adjacency: np.ndarray, base_channels: int = 64,\n",
    "                 num_blocks: int = 3, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        channels = [base_channels] * num_blocks\n",
    "        blocks = []\n",
    "        last_c = in_channels\n",
    "        for out_c in channels:\n",
    "            blocks.append(\n",
    "                STBlock(last_c, out_c, adjacency, stride=1, dropout=dropout)\n",
    "            )\n",
    "            last_c = out_c\n",
    "        self.st_blocks = nn.ModuleList(blocks)\n",
    "        self.fc = nn.Linear(last_c, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = x\n",
    "        for block in self.st_blocks:\n",
    "            out = block(out)\n",
    "        out = out.mean(dim=(-2, -1))\n",
    "        logits = self.fc(out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6668add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CTRGCNTwoStream(nn.Module):\n",
    "    def __init__(self, adjacency: np.ndarray,\n",
    "                 in_channels_coords: int = 4,\n",
    "                 in_channels_delta: int = 4,\n",
    "                 base_channels: int = 64,\n",
    "                 num_blocks: int = 3,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.stream_coords = CTRGCNMinimal(\n",
    "            in_channels_coords, base_channels, adjacency,\n",
    "            base_channels, num_blocks, dropout\n",
    "        )\n",
    "        self.stream_delta = CTRGCNMinimal(\n",
    "            in_channels_delta, base_channels, adjacency,\n",
    "            base_channels, num_blocks, dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(base_channels, 1)\n",
    "\n",
    "    def forward(self, coords_x: torch.Tensor, delta_x: torch.Tensor) -> torch.Tensor:\n",
    "        feat_A = self.stream_coords(coords_x)\n",
    "        feat_B = self.stream_delta(delta_x)\n",
    "        fused = feat_A + feat_B\n",
    "        logits = self.fc(fused)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class CTRGCNFourStream(nn.Module):\n",
    "    def __init__(self, adjacency: np.ndarray,\n",
    "                 base_channels: int = 64,\n",
    "                 dropout: float = 0.1,\n",
    "                 num_blocks: int = 3):\n",
    "        super().__init__()\n",
    "        self.stream_coords = CTRGCNMinimal(2, base_channels, adjacency, base_channels, num_blocks, dropout)\n",
    "        self.stream_delta = CTRGCNMinimal(2, base_channels, adjacency, base_channels, num_blocks, dropout)\n",
    "        self.stream_bone = CTRGCNMinimal(2, base_channels, adjacency, base_channels, num_blocks, dropout)\n",
    "        self.stream_bone_delta = CTRGCNMinimal(2, base_channels, adjacency, base_channels, num_blocks, dropout)\n",
    "        self.fc = nn.Linear(base_channels, 1)\n",
    "\n",
    "    def forward(self, coords_x, delta_x, bone_x, bone_delta_x):\n",
    "        f1 = self.stream_coords(coords_x)\n",
    "        f2 = self.stream_delta(delta_x)\n",
    "        f3 = self.stream_bone(bone_x)\n",
    "        f4 = self.stream_bone_delta(bone_delta_x)\n",
    "        fused = f1 + f2 + f3 + f4\n",
    "        return self.fc(fused)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea07329",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Data Loading & Batch Generation (Placeholder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12915ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_mouse_data(dataset: pd.DataFrame,\n",
    "                        traintest: str,\n",
    "                        traintest_directory: str | None = None,\n",
    "                        generate_single: bool = True,\n",
    "                        generate_pair: bool = True,\n",
    "                        config: CTRGCNConfig | None = None):\n",
    "    \"\"\"Generate batches of single-mouse or mouse-pair dataframes.\n",
    "\n",
    "    TODO: Paste your full generate_mouse_data implementation from CTRGCN-model-baseline.py here.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Paste generate_mouse_data implementation here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03d20c",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Sliding Window Extraction & Input Preparation (Placeholders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855747a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sliding_windows(single_mouse_df: pd.DataFrame,\n",
    "                           window: int = 90,\n",
    "                           stride: int = 30):\n",
    "    n_frames = len(single_mouse_df)\n",
    "    frames = single_mouse_df.index.to_numpy()\n",
    "    for start in range(0, n_frames - window + 1, stride):\n",
    "        end = start + window\n",
    "        window_df = single_mouse_df.iloc[start:end]\n",
    "        frame_indices = frames[start:end]\n",
    "        yield window_df, frame_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93eeb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_ctr_gcn_input(single_mouse_df: pd.DataFrame,\n",
    "                          ordered_joints: list[str],\n",
    "                          config: CTRGCNConfig | None = None):\n",
    "    \"\"\"Convert a single-mouse DataFrame into CTR-GCN-ready tensors.\n",
    "\n",
    "    TODO: Paste your full prepare_ctr_gcn_input implementation here,\n",
    "          including normalization, deltas, bones, and stream-mode branching.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Paste prepare_ctr_gcn_input implementation here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ccbd7",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Window Collection, Training & Inference (Placeholders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_ctr_gcn_windows(batches,\n",
    "                            ordered_joints: list[str],\n",
    "                            adjacency: np.ndarray,\n",
    "                            config: CTRGCNConfig,\n",
    "                            device: str = \"cpu\"):\n",
    "    \"\"\"Collect CTR-GCN windows and labels from batches.\n",
    "\n",
    "    TODO: Paste or implement the helper that loops over batches,\n",
    "          calls prepare_ctr_gcn_input, and aggregates tensors + labels.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Paste collect_ctr_gcn_windows implementation here.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_ctr_gcn_models(batches,\n",
    "                         ordered_joints: list[str],\n",
    "                         adjacency: np.ndarray,\n",
    "                         config: CTRGCNConfig,\n",
    "                         device: str = \"cpu\"):\n",
    "    \"\"\"Train one CTR-GCN model per action and save weights to disk.\n",
    "\n",
    "    TODO: Paste your train_ctr_gcn_models implementation here.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Paste train_ctr_gcn_models implementation here.\")\n",
    "\n",
    "\n",
    "def load_ctr_gcn_models(actions: list[str],\n",
    "                        adjacency: np.ndarray,\n",
    "                        config: CTRGCNConfig,\n",
    "                        device: str = \"cpu\"):\n",
    "    \"\"\"Load CTR-GCN models for the given actions and current stream_mode.\n",
    "\n",
    "    TODO: Paste your load_ctr_gcn_models implementation here.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Paste load_ctr_gcn_models implementation here.\")\n",
    "\n",
    "\n",
    "def submit_ctr_gcn(body_parts_tracked_str: str,\n",
    "                   switch_tr: str,\n",
    "                   model_dict: dict[str, nn.Module],\n",
    "                   config: CTRGCNConfig,\n",
    "                   device: str = \"cpu\") -> pd.DataFrame:\n",
    "    \"\"\"Run inference on test data and return a submission DataFrame.\n",
    "\n",
    "    TODO: Paste your submit_ctr_gcn implementation here.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Paste submit_ctr_gcn implementation here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90002806",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Dev Sanity Check (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if RUN_MODE == \"dev\":\n",
    "    print(\"Dev sanity-check placeholder.\")\n",
    "    print(\"Once you've pasted implementations:\")\n",
    "    print(\" - Load a tiny subset of train.csv\")\n",
    "    print(\" - Build ordered_joints, adjacency\")\n",
    "    print(\" - Generate a few batches via generate_mouse_data\")\n",
    "    print(\" - Call prepare_ctr_gcn_input on a single batch\")\n",
    "    print(\" - Instantiate CTRGCNMinimal and run a forward pass\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}